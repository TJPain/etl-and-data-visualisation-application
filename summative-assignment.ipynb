{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9169d50a",
   "metadata": {},
   "source": [
    "# Advanced Programming Summative Assignment\n",
    "\n",
    "Please see the README file (README.md) for a full overview of the project, installation instructions and running instructions. \n",
    "\n",
    "## Contents\n",
    "\n",
    "#### 1.0 [Package installations and import statements](#1.0-Package-installations-and-import-statements)\n",
    "\n",
    "#### 2.0 [Data extraction and cleaning](#2.0-Data-extraction-and-cleaning)\n",
    "\n",
    "2.1 [Read CSVs to dataframes and general data cleaning](#2.2-Merge-airport-and-frequency-dataframes)\n",
    "\n",
    "2.2 [Merge airport and frequency dataframes](#2.1-Read-CSVs-to-dataframes-and-general-data-cleaning)\n",
    "\n",
    "2.3 [Transform dataframes to JSON](#2.3-Transform-dataframes-to-JSON)\n",
    "\n",
    "#### 3.0 [Save current data and load previous data](#3.0-Save-current-data-and-load-previous-data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ac444f",
   "metadata": {},
   "source": [
    "### 1.0 Package installations and import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38ca82a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/tompain/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pandas-1.4.1               |   py38he9d5cce_1         9.3 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         9.3 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  pandas                               1.2.4-py38h23ab428_0 --> 1.4.1-py38he9d5cce_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pandas-1.4.1         | 9.3 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing missing packages\n",
    "%conda install --yes --prefix {sys.prefix} numpy\n",
    "%conda install --yes --prefix {sys.prefix} pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1453cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pprint\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import tkinter as tk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15799b3",
   "metadata": {},
   "source": [
    "### 2.0 Data extraction and cleaning\n",
    "\n",
    "A lot of the data processing is generic and not specific to the original data. This allows the application to handle other datasets from the same source. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5457f",
   "metadata": {},
   "source": [
    "#### 2.1 Read CSVs to dataframes and general data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11e41857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load and clean data functions.\"\"\"\n",
    "\n",
    "def load_date(): \n",
    "    \"\"\"Extract data from CSV files and add to pandas dataframes.\"\"\"\n",
    "    df_runways = pd.read_csv ('data/runways.csv', index_col=['id'])\n",
    "    df_frequencies = pd.read_csv ('data/airport-frequencies.csv', index_col=['id'])\n",
    "    # Prevent pandas from replacing the 'continent' value 'NA' (for North America) with NaN \n",
    "    df_airports = pd.read_csv ('data/airports.csv', keep_default_na=False)\n",
    "    return (df_runways, df_frequencies, df_airports)\n",
    "\n",
    "# The following functions carry out generic data cleaning on the dataframes\n",
    "\n",
    "def remove_missing_data(df_runways, df_frequencies, df_airports):\n",
    "    \"\"\"Remove any rows with all data missing.\"\"\"\n",
    "    df_airports.dropna(how='all')\n",
    "    df_runways.dropna(how='all')\n",
    "    df_frequencies.dropna(how='all')\n",
    "\n",
    "\n",
    "def remove_duplicates(df_runways, df_frequencies, df_airports):\n",
    "    \"\"\"Remove any duplicated rows.\"\"\"\n",
    "    df_airports.drop_duplicates()\n",
    "    df_runways.drop_duplicates()\n",
    "    df_frequencies.drop_duplicates()\n",
    "\n",
    "\n",
    "def remove_cols(df_runways, df_frequencies, df_airports):\n",
    "    \"\"\"Remove unneeded columns.\"\"\"\n",
    "    df_airports.drop(['keywords','home_link','local_code'], axis='columns', inplace=True)\n",
    "    df_runways.drop(['airport_ident'], axis='columns', inplace=True)\n",
    "    df_frequencies.drop(['airport_ident','description','type'], axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "def change_col_names(df_airports):\n",
    "    \"\"\"Change the airport column id name to airport_ref to align with other data.\"\"\"\n",
    "    df_airports.rename(columns={\"id\": \"airport_ref\"}, inplace=True)\n",
    "\n",
    "\n",
    "def remove_invalid(df_runways, df_frequencies, df_airports):\n",
    "    \"\"\"Remove rows that do not have a valid airport_ref.\"\"\"\n",
    "    df_airports = df_airports[df_airports['airport_ref'].apply(lambda x: str(x).isdigit())]\n",
    "    df_runways = df_runways[df_runways['airport_ref'].apply(lambda x: str(x).isdigit())]\n",
    "    df_frequencies = df_frequencies[df_frequencies['airport_ref'].apply(lambda x: str(x).isdigit())]\n",
    "    return (df_runways, df_frequencies, df_airports)\n",
    "\n",
    "\n",
    "def add_new_cols(df_airports):\n",
    "    \"\"\"Add columns to the Airports df for small, medium and large airports with binary values.\"\"\"\n",
    "    df_airports['small_airport'] = df_airports.type == 'small_airport'\n",
    "    df_airports['medium_airport'] = df_airports.type == 'medium_airport'\n",
    "    df_airports['large_airport'] = df_airports.type == 'large_airport'\n",
    "    df_airports['small_airport'] = df_airports['small_airport'].astype(int) \n",
    "    df_airports['medium_airport'] = df_airports['medium_airport'].astype(int) \n",
    "    df_airports['large_airport'] = df_airports['large_airport'].astype(int) \n",
    "    return(df_airports)\n",
    "\n",
    "\n",
    "def remove_closed(df_airports):\n",
    "    \"\"\"Remove closed airports.\"\"\"\n",
    "    df_airports = df_airports[(df_airports.type != 'closed')]\n",
    "    return(df_airports)\n",
    "\n",
    "\n",
    "def load_new_data():\n",
    "    \"\"\"Call load data and data cleaning functions.\"\"\"\n",
    "    df_runways, df_frequencies, df_airports = load_date()\n",
    "    remove_missing_data(df_runways, df_frequencies, df_airports)\n",
    "    remove_duplicates(df_runways, df_frequencies, df_airports)\n",
    "    remove_cols(df_runways, df_frequencies, df_airports)\n",
    "    change_col_names(df_airports)\n",
    "    remove_invalid(df_runways, df_frequencies, df_airports)\n",
    "    add_new_cols(df_airports)\n",
    "    remove_closed(df_airports)\n",
    "    return df_runways, df_frequencies, df_airports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c29c4fc",
   "metadata": {},
   "source": [
    "#### 2.2 Merge airport and frequency dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "44a1a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Merge airport and frequency dataframes into a single dataframe with one row per airport. Airports with multiple frequencies will have them stored in a list.\"\"\"\n",
    "\n",
    "def frequencies_to_list(df_frequencies):\n",
    "    \"\"\"Create a dictionary of airports each with a nested list of frequencies used by that airport.\"\"\"\n",
    "    # Initialise an empty dict to hold one key for each airport with a nested list of frequencies \n",
    "    frequencies_dict = {}\n",
    "\n",
    "    # Iterate through the frequencies creating one key for each airport with a list for it's frequencies \n",
    "    for index, row in df_frequencies.iterrows():\n",
    "        if row['airport_ref'] not in frequencies_dict:\n",
    "            frequencies_dict[row['airport_ref']] = [row['frequency_mhz']]\n",
    "        else:\n",
    "            frequencies_dict[row['airport_ref']].append(row['frequency_mhz'])\n",
    "    return frequencies_dict\n",
    "\n",
    "\n",
    "def merge_dataframes(frequencies_dict, df_airports):\n",
    "    \"\"\"Merge the airports dataframe with the dictionary of airports with nested lists of frequencies.\"\"\"\n",
    "    # Create a pandas series of airports (as index) and frequency lists \n",
    "    df_frequencies_series = pd.Series(frequencies_dict, name='df_frequencies_series')\n",
    "    # Rename the column titles to align with other data \n",
    "    df_airports_frequencies = df_frequencies_series.to_frame()\n",
    "    df_airports_frequencies.index.name = 'airport_ref'\n",
    "    # Convert to dataframe and merge with airports dataframe \n",
    "    df_airports_frequencies.rename(columns={'df_frequencies_series': 'frequency_mhz'}, inplace = True)\n",
    "    df_airports_frequencies = pd.merge(df_airports, df_airports_frequencies, on=\"airport_ref\", how = 'left')\n",
    "    return df_airports_frequencies\n",
    "\n",
    "\n",
    "def merge_airports_frequencies(df_frequencies, df_airports):\n",
    "    \"\"\"Call merge functions to merge airports with their communication frequencies.\"\"\"\n",
    "    frequencies_dict = frequencies_to_list(df_frequencies)\n",
    "    df_airports_frequencies = merge_dataframes(frequencies_dict, df_airports)\n",
    "    return df_airports_frequencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fbfbec",
   "metadata": {},
   "source": [
    "#### 2.3 Transform dataframes to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05fb3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_json(df_airports_frequencies, df_runways):\n",
    "    \"\"\"Translate dataframe data into JSON objects.\"\"\"\n",
    "    # write combined airport and frequency data to JSON\n",
    "    airports_frequencies_json = df_airports_frequencies.to_json(orient = 'records')\n",
    "    airports_frequencies_json_list = json.loads(airports_frequencies_json)\n",
    "    # write runways data to JSON\n",
    "    runways_json = df_runways.to_json(orient = 'records')\n",
    "    runways_json_list = json.loads(runways_json)\n",
    "    return airports_frequencies_json_list, runways_json_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d65de7",
   "metadata": {},
   "source": [
    "### 3.0 Save current data and load previous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60fd2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(airports_frequencies_json_list, runways_json_list):\n",
    "    \"\"\"Save current data to JSON files in the 'saved-data' folder.\"\"\"\n",
    "    with open('./saved-data/airports_frequencies.json', 'w') as outfile:\n",
    "        json.dump(airports_frequencies_json_list, outfile)\n",
    "    with open('./saved-data/runways_json_list.json', 'w') as outfile:\n",
    "        json.dump(runways_json_list, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91e3ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load previously saved data from JSON files in the 'saved-data' folder\"\"\"\n",
    "    with open('./saved-data/airports_frequencies.json', 'r') as infile:\n",
    "        loaded_airports_frequencies = json.load(infile)\n",
    "    with open('./saved-data/runways_json_list.json', 'r') as infile:\n",
    "        loaded_runways = json.load(infile)\n",
    "    return loaded_airports_frequencies, loaded_runways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb169edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUI code\n",
    "\n",
    "df_runways, df_frequencies, df_airports = load_new_data()\n",
    "df_airports_frequencies = merge_airports_frequencies(df_frequencies, df_airports)\n",
    "airports_frequencies_json_list, runways_json_list = transform_to_json(df_airports_frequencies, df_runways)\n",
    "save_data(airports_frequencies_json_list, runways_json_list)\n",
    "loaded_airports_frequencies, loaded_runways = load_data()\n",
    "# pprint.pprint(loaded_airports_frequencies[1])\n",
    "# print(type(loaded_airports_frequencies[1]))\n",
    "# print(\" \")\n",
    "# pprint.pprint(airports_frequencies_json_list[1])\n",
    "# print(type(airports_frequencies_json_list[1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
